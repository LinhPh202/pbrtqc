import streamlit as st
import pandas as pd
import numpy as np
import scipy.stats as stats

# =========================================================
# üõ†Ô∏è PH·∫¶N 1: X·ª¨ L√ù D·ªÆ LI·ªÜU & CACHING
# =========================================================

@st.cache_data(show_spinner=False)
def load_data(file_train, file_verify, col_res, col_day):
    try:
        df_train = pd.read_excel(file_train)
        df_verify = pd.read_excel(file_verify)
        
        # Lo·∫°i b·ªè d√≤ng tr·ªëng
        df_train = df_train.dropna(subset=[col_res])
        df_verify = df_verify.dropna(subset=[col_res, col_day])
        
        # S·∫Øp x·∫øp Verify theo th·ª© t·ª± xu·∫•t hi·ªán (quan tr·ªçng cho t√≠nh li√™n t·ª•c)
        # Gi·∫£ ƒë·ªãnh file excel ƒë√£ s·∫Øp x·∫øp theo th·ªùi gian, n·∫øu kh√¥ng th√¨ c·∫ßn sort
        # df_verify = df_verify.sort_values(by=col_day) 
        
        return df_train, df_verify
    except Exception as e:
        return None, None

def find_optimal_truncation(data_array, max_cut_percent=0.10, steps=10):
    """T√¨m kho·∫£ng c·∫Øt t·ªëi ∆∞u (Auto Mode)"""
    calc_data = data_array
    if len(data_array) > 5000:
        np.random.seed(42)
        calc_data = np.random.choice(data_array, 5000, replace=False)
        
    best_p = -1
    best_range = (data_array.min(), data_array.max())
    
    cuts = np.linspace(0, max_cut_percent, steps)
    sorted_data = np.sort(calc_data)
    n = len(sorted_data)
    
    for left_cut in cuts:
        for right_cut in cuts:
            if left_cut + right_cut >= 0.5: continue
            s = int(n * left_cut)
            e = int(n * (1 - right_cut))
            subset = sorted_data[s:e]
            
            if len(subset) > 20:
                stat, p_val = stats.normaltest(subset)
                if p_val > best_p:
                    best_p = p_val
                    lower = np.percentile(data_array, left_cut * 100)
                    upper = np.percentile(data_array, (1 - right_cut) * 100)
                    best_range = (lower, upper)
    return best_range

# =========================================================
# üß† PH·∫¶N 2: ENGINE M√î PH·ªéNG (CONTINUOUS MODE)
# =========================================================

class PBRTQCEngine:
    def __init__(self, df_train, df_verify, col_res, col_day, trunc_range):
        self.trunc_min, self.trunc_max = trunc_range
        self.col_res = col_res
        self.col_day = col_day
        
        # 1. Training Data (ƒê·ªÉ t√≠nh Limit)
        raw_train = df_train[col_res].values
        self.train_clean = raw_train[(raw_train >= self.trunc_min) & (raw_train <= self.trunc_max)]
        
        # 2. Verify Data (X·ª≠ l√Ω chu·ªói li√™n t·ª•c)
        # L·ªçc b·ªè ngo·∫°i lai nh∆∞ng GI·ªÆ NGUY√äN TH·ª® T·ª∞ ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh li√™n t·ª•c c·ªßa th·ªùi gian
        # L∆∞u √Ω: N·∫øu l·ªçc b·ªè d√≤ng th√¨ index s·∫Ω b·ªã nh·∫£y, tuy nhi√™n SMA/EWMA s·∫Ω t√≠nh tr√™n c√°c ƒëi·ªÉm d·ªØ li·ªáu c√≤n l·∫°i li·ªÅn k·ªÅ nhau.
        self.df_verify_clean = df_verify[
            (df_verify[col_res] >= self.trunc_min) & 
            (df_verify[col_res] <= self.trunc_max)
        ].copy()
        
        # T·∫°o m·∫£ng d·ªØ li·ªáu to√†n c·ª•c (Global Array)
        self.global_vals = self.df_verify_clean[col_res].values.astype(float)
        self.global_days = self.df_verify_clean[col_day].values

        # T·∫°o b·∫£n ƒë·ªì index cho t·ª´ng ng√†y: { "Day1": [start_idx, end_idx], ... }
        # Gi√∫p truy xu·∫•t nhanh v·ªã tr√≠ c·ªßa t·ª´ng ng√†y trong chu·ªói to√†n c·ª•c
        self.day_indices = {}
        unique_days = self.df_verify_clean[col_day].unique()
        
        # V√¨ d·ªØ li·ªáu ƒë√£ sort ho·∫∑c li·ªÅn m·∫°ch, ta t√¨m index start/end c·ªßa t·ª´ng ng√†y
        current_idx = 0
        for day in unique_days:
            count = len(self.df_verify_clean[self.df_verify_clean[col_day] == day])
            self.day_indices[day] = (current_idx, current_idx + count)
            current_idx += count

    def calculate_ma(self, values, method, param):
        """T√≠nh MA tr√™n to√†n b·ªô chu·ªói"""
        series = pd.Series(values)
        if method == 'SMA':
            return series.rolling(window=int(param)).mean().bfill().values
        elif method == 'EWMA':
            lam = 2 / (int(param) + 1)
            return series.ewm(alpha=lam, adjust=False).mean().values
        return values

    def determine_limits(self, method, param, target_fpr):
        """T√≠nh Limit t·ª´ Training Data"""
        ma_values = self.calculate_ma(self.train_clean, method, param)
        lower = np.percentile(ma_values, (target_fpr/2)*100)
        upper = np.percentile(ma_values, (1 - target_fpr/2)*100)
        return lower, upper

    def run_continuous_simulation(self, method, param, lcl, ucl, bias_pct, frequency=1, num_sims=None, fixed_inject_idx=None):
        """
        M√¥ ph·ªèng v·ªõi logic: MA t√≠nh xuy√™n su·ªët, Frequency t√≠nh tr√™n Index to√†n c·ª•c.
        """
        total_days = 0
        detected_days = 0
        false_positive_days = 0
        nped_list = []
        
        bias_factor = 1 + (bias_pct / 100.0)
        
        # 1. T√≠nh MA S·∫°ch to√†n c·ª•c (Global Clean MA)
        # T√≠nh 1 l·∫ßn d√πng chung cho vi·ªác check False Positive
        global_ma_clean = self.calculate_ma(self.global_vals, method, param)
        
        # M·∫£ng Index to√†n c·ª•c ƒë·ªÉ check Frequency
        # Ch·ªâ nh·ªØng index n√†o chia h·∫øt cho Frequency m·ªõi ƒë∆∞·ª£c coi l√† ƒëi·ªÉm ki·ªÉm tra h·ª£p l·ªá
        global_indices = np.arange(len(self.global_vals))
        valid_check_points = (global_indices % frequency == 0)

        # L·∫•y danh s√°ch ng√†y c·∫ßn ch·∫°y
        days_to_run = list(self.day_indices.keys())
        if num_sims and num_sims < len(days_to_run):
            days_to_run = days_to_run[:num_sims]

        for day_name in days_to_run:
            start_idx, end_idx = self.day_indices[day_name]
            day_len = end_idx - start_idx
            
            if day_len < 5: continue
            total_days += 1
            
            # --- X√ÅC ƒê·ªäNH ƒêI·ªÇM TI√äM L·ªñI (LOCAL INDEX -> GLOBAL INDEX) ---
            if fixed_inject_idx is not None:
                local_inject = min(fixed_inject_idx, day_len - 1)
                local_inject = max(1, local_inject)
            else:
                max_rnd = min(40, day_len - 2)
                if max_rnd < 1: max_rnd = 1
                local_inject = np.random.randint(1, max_rnd + 1)
            
            # Chuy·ªÉn ƒë·ªïi sang Index to√†n c·ª•c
            global_inject_idx = start_idx + local_inject
            # ------------------------------------------------------------

            # 2. CHECK FALSE POSITIVE (Tr√™n ƒë∆∞·ªùng Global Clean)
            # Ki·ªÉm tra trong kho·∫£ng [start_idx, global_inject_idx)
            # V√Ä ph·∫£i th·ªèa m√£n ƒëi·ªÅu ki·ªán Frequency
            
            # C·∫Øt v√πng c·∫ßn check
            region_mask = valid_check_points[start_idx : global_inject_idx]
            region_vals = global_ma_clean[start_idx : global_inject_idx]
            
            # L·ªçc nh·ªØng ƒëi·ªÉm ƒë√∫ng Frequency
            check_vals = region_vals[region_mask]
            
            if len(check_vals) > 0:
                alarms = (check_vals < lcl) | (check_vals > ucl)
                if np.any(alarms):
                    false_positive_days += 1
                    continue # Ng√†y n√†y coi nh∆∞ fail do b√°o gi·∫£, sang ng√†y ti·∫øp

            # 3. CHECK DETECTION (C·∫ßn t√≠nh l·∫°i MA)
            # T·∫°o b·∫£n sao d·ªØ li·ªáu to√†n c·ª•c v√† ti√™m l·ªói
            # L∆∞u √Ω: Ta ch·ªâ c·∫ßn ti√™m l·ªói t·ª´ global_inject_idx ƒë·∫øn h·∫øt ng√†y ƒë√≥ (end_idx).
            # V√¨ logic l√† "Ng√†y h√¥m sau reset l·ªói", n√™n ta kh√¥ng c·∫ßn ti√™m l·ªói cho c√°c ng√†y sau ƒë√≥.
            # Tuy nhi√™n, MA c·∫ßn ƒë∆∞·ª£c t√≠nh l·∫°i ƒë·ªÉ ph·∫£n √°nh s·ª± thay ƒë·ªïi.
            
            # T·ªëi ∆∞u: ƒê·ªÉ t√≠nh MA ch√≠nh x√°c t·∫°i th·ªùi ƒëi·ªÉm global_inject_idx, ta c·∫ßn l·ªãch s·ª≠ tr∆∞·ªõc ƒë√≥.
            # C√°ch an to√†n nh·∫•t: Copy to√†n b·ªô m·∫£ng, s·ª≠a ƒëo·∫°n b·ªã l·ªói, t√≠nh l·∫°i MA.
            
            temp_global_vals = self.global_vals.copy()
            # Ti√™m l·ªói t·ª´ ƒëi·ªÉm b·∫Øt ƒë·∫ßu ƒë·∫øn h·∫øt ng√†y h√¥m ƒë√≥
            temp_global_vals[global_inject_idx : end_idx] *= bias_factor
            
            # T√≠nh l·∫°i MA (Biased)
            global_ma_biased = self.calculate_ma(temp_global_vals, method, param)
            
            # Ki·ªÉm tra v√πng [global_inject_idx, end_idx)
            # V√Ä th·ªèa m√£n Frequency
            region_mask_post = valid_check_points[global_inject_idx : end_idx]
            region_vals_post = global_ma_biased[global_inject_idx : end_idx]
            
            check_vals_post = region_vals_post[region_mask_post]
            
            if len(check_vals_post) > 0:
                alarms_post = (check_vals_post < lcl) | (check_vals_post > ucl)
                if np.any(alarms_post):
                    detected_days += 1
                    
                    # T√¨m v·ªã tr√≠ Alarm ƒë·∫ßu ti√™n trong m·∫£ng ƒë√£ filter (check_vals_post)
                    # Tuy nhi√™n ƒë·ªÉ t√≠nh NPed ch√≠nh x√°c, ta c·∫ßn bi·∫øt index th·ª±c
                    
                    # L·∫•y index th·ª±c trong v√πng c·∫Øt
                    indices_in_region = np.arange(global_inject_idx, end_idx)
                    # L·ªçc index theo frequency v√† alarm
                    alarm_indices = indices_in_region[valid_check_points[global_inject_idx : end_idx] & ((global_ma_biased[global_inject_idx:end_idx] < lcl) | (global_ma_biased[global_inject_idx:end_idx] > ucl))]
                    
                    if len(alarm_indices) > 0:
                        first_alarm_idx = alarm_indices[0]
                        # NPed = S·ªë m·∫´u b·ªánh nh√¢n tr√¥i qua k·ªÉ t·ª´ l√∫c ti√™m l·ªói
                        nped = first_alarm_idx - global_inject_idx + 1
                        nped_list.append(nped)

        metrics = {
            "Total Days": total_days,
            "Detected (%)": round(detected_days / total_days * 100, 1) if total_days > 0 else 0,
            "False Positive (%)": round(false_positive_days / total_days * 100, 1) if total_days > 0 else 0,
            "ANPed": round(np.mean(nped_list), 1) if nped_list else "N/A",
            "Median NPed": round(np.median(nped_list), 1) if nped_list else "N/A",
            "95th NPed": round(np.percentile(nped_list, 95), 1) if nped_list else "N/A"
        }
        return metrics

# =========================================================
# üñ•Ô∏è PH·∫¶N 3: GIAO DI·ªÜN STREAMLIT
# =========================================================

st.set_page_config(layout="wide", page_title="PBRTQC Simulator Pro")

st.title("üè• PBRTQC Continuous Simulator")
st.markdown("""
H·ªá th·ªëng m√¥ ph·ªèng PBRTQC v·ªõi logic **Continuous Monitoring**:
- **MA Calculation:** T√≠nh xuy√™n su·ªët qua c√°c ng√†y (Ng√†y 2 k·∫ø th·ª´a d·ªØ li·ªáu Ng√†y 1).
- **Frequency:** T√≠nh d·ª±a tr√™n Index to√†n c·ª•c (V√≠ d·ª• Freq=5: check t·∫°i m·∫´u 5, 10, 15... b·∫•t k·ªÉ ng√†y).
- **Simulation:** Reset tr·∫°ng th√°i l·ªói khi qua ng√†y m·ªõi.
""")

with st.sidebar:
    st.header("1. Upload Data")
    f_train = st.file_uploader("Training Data (.xlsx)", type='xlsx')
    f_verify = st.file_uploader("Verify Data (.xlsx)", type='xlsx')
    
    st.divider()
    st.header("2. Settings")
    bias_pct = st.number_input("Bias (%)", value=5.0, step=0.5)
    target_fpr = st.slider("Target FPR (%)", 0.1, 10.0, 2.0, 0.1) / 100
    model = st.selectbox("Model", ["EWMA", "SMA"])
    max_days = st.slider("Max Simulation Days", 10, 5000, 100, help="S·ªë l∆∞·ª£ng ng√†y t·ªëi ƒëa mu·ªën ch·∫°y m√¥ ph·ªèng.")
    
    st.subheader("Injection Mode")
    inject_mode = st.radio("Ch·∫ø ƒë·ªô th√™m l·ªói:", ["Ng·∫´u nhi√™n (Random 1-40)", "C·ªë ƒë·ªãnh (Fixed Point)"])
    fixed_point = None
    if inject_mode == "C·ªë ƒë·ªãnh (Fixed Point)":
        fixed_point = st.number_input("V·ªã tr√≠ m·∫´u b·∫Øt ƒë·∫ßu l·ªói (trong ng√†y):", min_value=1, value=20)

    # --- TRUNCATION SETTINGS ---
    st.divider()
    st.header("3. Truncation Limit")
    trunc_mode = st.radio("Ph∆∞∆°ng ph√°p c·∫Øt:", ["Auto (T·ª± ƒë·ªông)", "Manual (Th·ªß c√¥ng)"])
    
    manual_min = 0.0
    manual_max = 1000.0
    
    if trunc_mode == "Manual (Th·ªß c√¥ng)":
        c_min, c_max = st.columns(2)
        manual_min = c_min.number_input("Min Value", value=0.0)
        manual_max = c_max.number_input("Max Value", value=100.0)

if f_train and f_verify:
    df_temp = pd.read_excel(f_train, nrows=1)
    all_cols = df_temp.columns.tolist()
    
    c1, c2 = st.columns(2)
    col_res = c1.selectbox("C·ªôt K·∫øt qu·∫£ (Results)", all_cols)
    col_day = c2.selectbox("C·ªôt Ng√†y (Days)", all_cols)

    # --- INPUT BLOCK SIZE ---
    st.divider()
    st.subheader(f"4. C·∫•u h√¨nh tham s·ªë (Block Size) cho {model}")
    
    col_case1, col_case2, col_case3 = st.columns(3)
    cases_config = []
    
    def create_case_input(col, idx):
        with col:
            st.markdown(f"**Case {idx}**")
            bs = st.number_input(f"Block Size (N)", value=20*idx, key=f"bs{idx}", min_value=2)
            freq = 1
            if model == "SMA":
                freq = st.number_input("Frequency", value=1, key=f"freq{idx}", min_value=1)
            # N·∫øu l√† EWMA, Frequency v·∫´n c√≥ th·ªÉ √°p d·ª•ng cho vi·ªác Check Alarm (Sampling)
            if model == "EWMA":
                 freq = st.number_input("Frequency (Check Interval)", value=1, key=f"freq_ewma{idx}", min_value=1)
            return {'bs': bs, 'freq': freq}

    cases_config.append(create_case_input(col_case1, 1))
    cases_config.append(create_case_input(col_case2, 2))
    cases_config.append(create_case_input(col_case3, 3))

    if st.button("üöÄ Run Simulation"):
        with st.spinner("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu v√† ch·∫°y m√¥ ph·ªèng (C√≥ th·ªÉ m·∫•t ch√∫t th·ªùi gian)..."):
            df_train, df_verify = load_data(f_train, f_verify, col_res, col_day)
            
            if df_train is not None:
                # --- X·ª¨ L√ù TRUNCATION ---
                trunc_range = (0, 0)
                data_train_vals = df_train[col_res].dropna().values
                
                if trunc_mode == "Auto (T·ª± ƒë·ªông)":
                    trunc_range = find_optimal_truncation(data_train_vals)
                    st.success(f"‚úÖ Auto Truncation: [{trunc_range[0]:.2f} - {trunc_range[1]:.2f}]")
                else:
                    trunc_range = (manual_min, manual_max)
                    st.info(f"üîß Manual Truncation: [{trunc_range[0]:.2f} - {trunc_range[1]:.2f}]")
                
                # Kh·ªüi t·∫°o Engine
                engine = PBRTQCEngine(df_train, df_verify, col_res, col_day, trunc_range)
                
                results = []
                prog_bar = st.progress(0)
                
                for i, case in enumerate(cases_config):
                    lcl, ucl = engine.determine_limits(model, case['bs'], target_fpr)
                    
                    metrics = engine.run_continuous_simulation(
                        model, case['bs'], lcl, ucl, bias_pct,
                        frequency=case['freq'],
                        num_sims=max_days, 
                        fixed_inject_idx=fixed_point
                    )
                    
                    res_row = {
                        "Case": f"N={case['bs']}",
                        "Frequency": case['freq'],
                        "LCL": round(lcl, 2), "UCL": round(ucl, 2),
                        **metrics
                    }
                    results.append(res_row)
                    prog_bar.progress((i+1)/len(cases_config))
                
                st.subheader("üìä B·∫£ng K·∫øt qu·∫£ ƒê√°nh gi√°")
                st.dataframe(pd.DataFrame(results).style.highlight_max(subset=['Detected (%)'], color='#d1ffbd'), use_container_width=True)
                
            else:
                st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c d·ªØ li·ªáu Training/Verify.")
